{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will implement a Convoulutional Neural Network (CNN) using PyTorch for CIFAR-10 Classification.\n",
        "\n",
        "Expectations: Please provide solutions to the questions in the cells at the end of the notebook."
      ],
      "metadata": {
        "id": "P4uZ_B-B2qPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqg8SEXq55vV"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim, utils\n",
        "from torchvision import models,transforms\n",
        "from torchvision.datasets import CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the device to the GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#Training function\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    for X, y in dataloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        yhat = model(X)\n",
        "        loss = loss_fn(yhat, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "#Testing function (accuracy)\n",
        "def test_accuracy(dataloader, model, device):\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = torch.argmax(model(X), dim=1)\n",
        "\n",
        "            correct += torch.sum(torch.eq(yhat, y)).item()\n",
        "            total += X.shape[0]\n",
        "\n",
        "        return f\"{round(100*correct/total, 4)}%\""
      ],
      "metadata": {
        "id": "6vP29kihi4z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) datasets which is sub-dataset of CIFAR-100 Dataset. The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "We will use pytorch datasets to fetch the CIFAR-10 dataset as it provides a handy way to get and use the dataset. More information about pytorch datasets [here](https://pytorch.org/vision/stable/datasets.html)."
      ],
      "metadata": {
        "id": "LnCBbq3_MDA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating CIFAR-10 datasets\n",
        "dataset_total = CIFAR10(root='./datasets', train=True, download=True, transform = transforms.ToTensor())\n",
        "dataset_test = CIFAR10(root='./datasets', train=False, download=True, transform = transforms.ToTensor())\n",
        "\n",
        "# Splitting the total dataset into training and validation sets\n",
        "n_total = len(dataset_total)\n",
        "n_train = int(0.8*n_total)\n",
        "n_validation = n_total - n_train\n",
        "dataset_train, dataset_validation = utils.data.random_split(dataset_total, [n_train,n_validation])\n",
        "\n",
        "#Creating dataloaders\n",
        "dataloader_train = utils.data.DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
        "dataloader_validation = utils.data.DataLoader(dataset_validation, batch_size=64, shuffle=False)\n",
        "dataloader_test = utils.data.DataLoader(dataset_test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAdxvEwxDeA6",
        "outputId": "13b5ccf2-01e5-490b-dd27-5a21757a6f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1: Define a 2 layer simple NN for CIFAR-10 classificaiton"
      ],
      "metadata": {
        "id": "mriJazNZ6SVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining our neural network\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lin1 = nn.Linear(32*32*3, 80)\n",
        "        self.activ1 = nn.ReLU()\n",
        "        self.out = nn.Linear(80, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32*3)\n",
        "        x = self.lin1(x)\n",
        "        x = self.activ1(x)\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0P2MP2heMfdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2: Define a CNN with 2 conv layer and 2 linear layers for CIFAR-10 classificaiton"
      ],
      "metadata": {
        "id": "ji48-AfL7zWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining our convolutional neural network\n",
        "class CNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 3, 1)\n",
        "        self.activ1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(10, 5, 3, 1)\n",
        "        self.activ2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.linear3 = nn.Linear(6*6*5, 100)\n",
        "        self.activ3 = nn.ReLU()\n",
        "        self.out = nn.Linear(100, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.activ1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.activ2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 6*6*5)\n",
        "        x = self.linear3(x)\n",
        "        x = self.activ3(x)\n",
        "        x = self.out(x)\n",
        "        x = self.softmax(x)\n",
        "        return (x)"
      ],
      "metadata": {
        "id": "bt8KntpVMq1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3: Train both networks for 10 epochs and compare their performance"
      ],
      "metadata": {
        "id": "Lwmx2FZq7_KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining an instance of our network and other parameters required for training\n",
        "net = Net().to(device)\n",
        "loss_fn_net = nn.CrossEntropyLoss()\n",
        "optimizer_net = optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "#Training our network\n",
        "epochs_net = 10\n",
        "for epoch_net in range(epochs_net):\n",
        "    train(dataloader_train, net, loss_fn_net, optimizer_net, device)"
      ],
      "metadata": {
        "id": "iBz9r7lxP2pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining an instance of our convolutional network and other parameters required for training\n",
        "cnet = CNet().to(device)\n",
        "loss_fn_cnet = nn.CrossEntropyLoss()\n",
        "optimizer_cnet = optim.Adam(cnet.parameters(), lr=1e-3)\n",
        "\n",
        "#Training our convolutional network\n",
        "epochs_cnet = 10\n",
        "for epoch_cnet in range(epochs_cnet):\n",
        "    train(dataloader_train, cnet, loss_fn_cnet, optimizer_cnet, device)"
      ],
      "metadata": {
        "id": "B7lLbGx2Q5k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of our network on the train and validation datasets\n",
        "print(test_accuracy(dataloader_train, net, device))\n",
        "print()\n",
        "print(test_accuracy(dataloader_validation, net, device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8NPENmoOiF3",
        "outputId": "a70b4e0c-683d-4c8f-e360-20491ffc91e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36.005%\n",
            "\n",
            "34.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of our convolutional network on the train and validation datasets\n",
        "print(test_accuracy(dataloader_train, cnet, device))\n",
        "print()\n",
        "print(test_accuracy(dataloader_validation, cnet, device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU5RSMbFP1tN",
        "outputId": "e75cbf39-dc03-49c2-eb78-1a39c65f6df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51.135%\n",
            "\n",
            "47.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4: Compare the accuracy of both networks on the test set"
      ],
      "metadata": {
        "id": "cC4IvFLD-kHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of our network on the test dataset\n",
        "print(test_accuracy(dataloader_test, net, device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaUeNTBIRkT0",
        "outputId": "120e7775-b25a-4427-d573-1e05cb68159b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of our convolutional network on the test dataset\n",
        "print(test_accuracy(dataloader_test, cnet, device))"
      ],
      "metadata": {
        "id": "8aJ72N_WTcjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1ec3fa-c57e-415c-9e33-2fd9a0b6aca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simple neural network gives an accuracy of ~35%, and the convolutional network gives an accuracy of ~45%. It makes sense that the convoultional network gives a bit better results, and it also makes sense that both don't have very high accuracy since they don't have many layers and parameters."
      ],
      "metadata": {
        "id": "dGbyNiDaJaBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transfer Learning\n",
        "\n",
        "Transfer learning means taking the relevant parts of a pre-trained machine learning model and applying it to a new but similar problem. Transfer learning brings a range of benefits to the development process of machine learning models. The main benefits of transfer learning include the saving of resources and improved efficiency when training new models. It can also help with training models when only unlabelled datasets are available, as the bulk of the model will be pre-trained."
      ],
      "metadata": {
        "id": "DthgIi9AMdfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5: Fine-tune ResNet18 model trained on ImageNet for CIFAR10 dataset"
      ],
      "metadata": {
        "id": "amQ523TqTyhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading a pre-trained ResNet18 model\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "#Making pretraind values immutable\n",
        "for param_resnet in resnet.parameters():\n",
        "    param_resnet.requires_grad = False\n",
        "\n",
        "#Making adjustments to the layers\n",
        "resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "resnet.maxpool = nn.Identity()\n",
        "resnet.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "\n",
        "#Sending the network to the GPU\n",
        "resnet = resnet.to(device)"
      ],
      "metadata": {
        "id": "vHS7-5pvSq-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341293fb-a07f-4775-b7d5-5c87bde6d39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining other parameters required for training\n",
        "loss_fn_resnet = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = optim.Adam(resnet.parameters(), lr=1e-3)\n",
        "\n",
        "#Training our fine-tuned network\n",
        "epochs_resnet = 10\n",
        "for epoch_resnet in range(epochs_resnet):\n",
        "    train(dataloader_train, resnet, loss_fn_resnet, optimizer_resnet, device)"
      ],
      "metadata": {
        "id": "qjh7oFNMZLtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of our fine-tuned network on the train and validation datasets\n",
        "print(test_accuracy(dataloader_train, resnet, device))\n",
        "print()\n",
        "print(test_accuracy(dataloader_validation, resnet, device))"
      ],
      "metadata": {
        "id": "0PNNTiWscQpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7ad017-fba8-40b6-b638-9167e2d19f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69.2175%\n",
            "\n",
            "66.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6: Compare the accuracy of simple CNN and ResNet18 model on the test set"
      ],
      "metadata": {
        "id": "GpeMM202cAit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy of our fine-tuned network on the test dataset\n",
        "print(test_accuracy(dataloader_test, resnet, device))"
      ],
      "metadata": {
        "id": "WaWFmIWPSrcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b546ed-478a-4bb0-c51a-c44a0e760230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I dropped the kernel size (and stride) of the first convolutional layer because CIFAR-10 images are 32x32 and I wanted to perserve more detail insted of the usual 7x7 kernel. I also changed the number of recognizable classes from the default 1000 to 10. These modifications give an accuracy ~75% which is significantly higher than the previous ~35% and ~45%. If we wanted to go even higher, we could try fine-tuning more layers."
      ],
      "metadata": {
        "id": "5BPoqUzwKLKm"
      }
    }
  ]
}